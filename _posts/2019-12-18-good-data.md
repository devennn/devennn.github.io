---
layout: post
title: Good data trumps good algorithm
---

The first time I played with beginner Kaggle challenge, Titanic, I am so excited about the possibilities of Machine learning. But not so on data preprocessing. I want to get my hands dirty with the Scikit-learn algorithm quickly. 

It took me a day to do the necessary data preprocessing. I fill up the empty cells, replace strings with one-hot encoding and removing columns with too many empty cells. I end up having formatted dataset with lots of columns, and I thought that would be enough.

Then comes the best part, model training. I made a function which runs all the data using some famous algorithm such as Random Forest, SVM, Linear Regression, AdaBoost and KNN. My strategy is simple. 

- Run the data using all algorithm
- Evaluate result for highest accuracy.
- Run grid search

For me, that seems to be a good strategy. Whatever the grid search suggest is the best parameters of the model. I got 67%.

Whatever I tried to tweak, it does not get better +-0.5%. That makes me wonder, What more can I do?. Then I came across a suggestion to group the passengers' age. For example, 0 - 7 is children, 30 - 100 is adult, and so on. Rerun the new data, and accuracy goes up to 70%.

That is when I know, preprocessing is very important in producing a predictive model with Machine learning. Thus, whenever I do a simple project, I remind myself, good data create a good model. Remember feature Engineering!
