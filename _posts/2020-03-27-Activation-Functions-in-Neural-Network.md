---
layout: post
title: Activation Functions in Neural Network
published: false
---

1. Linear
2. Relu
3. Softmax
4. Sigmoid
5. Tanh
